= DataStax Apache Kafka Connector
:slug: streaming-data-with-the-datastax-apache-kafka-connector

Deploy the DataStax Apache Kafka™ Connector to stream records from an Apache Kafka topic to your DataStax Astra database.

The DataStax Apache Kafka Connector download package includes a sample JSON properties file (`dse-sink-distributed.json.sample`).
Use the sample file as a reference when configuring your deployment.
The `dse-sink-distributed.json.sample` file is located in the `conf` directory of the DataStax Apache Kafka Connector distribution package.

==Prerequisites
. https://docs.datastax.com/en/kafka/doc/kafka/install/kafkaInstall.html[Download and install] the DataStax Apache Kafka Connector.
. Configure the distributed worker configuration file `connect-distributed.properties` to fit your needs.
Use https://github.com/datastax/kafka-examples/blob/master/producers/src/main/java/json/connect-distributed-json.properties[this example] from DataStax as a starting point.
Specify the converter for the `key.converter` and `value.converter` properties that matches the form of your Kafka data.
See https://docs.confluent.io/current/connect/userguide.html#configuring-converters[Configuring converters] in the Confluent documentation for more information on these properties.

==Procedure
. From the directory where you installed Apache Kafka, start the distributed worker:
```
$ bin/connect-distributed.sh config/connect-distributed.properties
```

The worker startup process outputs a large number of informational messages.
The following message displays after the process completes: `[2019-10-13 19:49:25,385] INFO Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:852)`
. Configure the JSON configuration file (such as dse-sink.json) to use the Astra xref:obtaining-database-credentials.adoc[secure connect bundle].
```
{ "name": "dse-sink",     "config":
  { "connector.class": "com.datastax.kafkaconnector.DseSinkConnector",
    "cloud.secureConnectBundle": "/path/to/secure-connect-database-name.zip",
    "auth.username": "username",
    "auth.password": "password" ...
  }
}
```

*name*   Unique name for the connector. Default: `dse-sink`

*connector.class*   DataStax connector Java class provided in the `kafka-connect-dse-N.N.N.jar`. Default: `com.datastax.kafkaconnector.DseSinkConnector`

*cloud.secureConnectBundle*   The full path to the secure connect bundle for your DataStax Astra database (`secure-connect-**database_name**.zip`).
Download the secure connect bundle from the DataStax Cloud console.
If this option is specified, you must also include the auth.username and auth.password for the database user.

*auth.username*   Astra database username.

[NOTE]
====
When authorization is enabled, the DataStax connector login role must have a minimum of `modify` privileges on tables receiving data from the DataStax Apache Kafka® Connector.
====

**auth.password** Astra database password for the specified username.

. Register the connector configuration with the distributed worker:
```
$ curl -X POST -H "Content-Type: application/json" -d @dse-sink.json "http://ip:port/connectors"
```

*ip* and *port* are the IP address and port number of the Kafka worker.
Use the same port as the `rest.port` parameter set in `connect-distributed.properties`.
The default port is 8083.
[NOTE]
====
You configured the `dse-sink.json` or `dse-sink.properties` file when installing the DataStax Apache Kafka Connector.
====
